{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nlpaug.augmenter.word import ContextualWordEmbsAug\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      tweet off_label hs_label\n",
      "count                  8887      8887     8887\n",
      "unique                 8887         2        6\n",
      "top      ÿ±ÿØŸäŸÜÿß ÿπ ÿßŸÑÿ™ÿ∑ŸÜÿ≤ üòèüëäüèª   NOT_OFF   NOT_HS\n",
      "freq                      1      5715     7928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>off_label</th>\n",
       "      <th>hs_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÿ±ÿØŸäŸÜÿß ÿπ ÿßŸÑÿ™ÿ∑ŸÜÿ≤ üòèüëäüèª</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT_HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ÿàÿµÿßÿ±ÿ™ ŸÅÿ∑ÿßŸäÿ± ÿßŸÑÿ®ŸÇÿßŸÑÿßÿ™ ÿ∫ÿ∞ÿßÿ° ÿµÿ≠Ÿä üëéüèª</td>\n",
       "      <td>NOT_OFF</td>\n",
       "      <td>NOT_HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÿ±Ÿàÿ≠Ÿä ŸÑÿ®ÿ±ŸäÿØŸá ÿ™ŸÑŸÇŸäŸÜ ÿßÿ¥ÿ®ÿßŸá ŸÉÿ´Ÿäÿ± ÿ®ÿ≥ ŸÖÿßÿ≠ÿØ ÿ≤ŸäŸÉŸÖ ŸÖÿ¥ŸÅ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT_HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ŸÖÿ¥ ÿ®ÿßŸäŸÜ ÿ≠ÿßÿ¨Ÿá ÿÆÿßŸÑÿµ üò£ŸÖÿ¥ ÿπÿßÿ±ŸÅ ÿ®ŸÇŸâ üòî</td>\n",
       "      <td>NOT_OFF</td>\n",
       "      <td>NOT_HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ÿßŸÑŸäŸàŸÖ_ÿßŸÑÿßÿ´ŸÜŸäŸÜüëè ŸäŸÇŸàŸÑŸÉ :%90  ŸÖŸÜ ÿßŸÑŸÖÿ≥ŸÑŸÖŸäŸÜ ÿπŸÜÿØŸáŸÖ ...</td>\n",
       "      <td>NOT_OFF</td>\n",
       "      <td>NOT_HS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet off_label hs_label\n",
       "0                                 ÿ±ÿØŸäŸÜÿß ÿπ ÿßŸÑÿ™ÿ∑ŸÜÿ≤ üòèüëäüèª       OFF   NOT_HS\n",
       "1                  Ÿàÿµÿßÿ±ÿ™ ŸÅÿ∑ÿßŸäÿ± ÿßŸÑÿ®ŸÇÿßŸÑÿßÿ™ ÿ∫ÿ∞ÿßÿ° ÿµÿ≠Ÿä üëéüèª    NOT_OFF   NOT_HS\n",
       "2   ÿ±Ÿàÿ≠Ÿä ŸÑÿ®ÿ±ŸäÿØŸá ÿ™ŸÑŸÇŸäŸÜ ÿßÿ¥ÿ®ÿßŸá ŸÉÿ´Ÿäÿ± ÿ®ÿ≥ ŸÖÿßÿ≠ÿØ ÿ≤ŸäŸÉŸÖ ŸÖÿ¥ŸÅ...       OFF   NOT_HS\n",
       "3                   ŸÖÿ¥ ÿ®ÿßŸäŸÜ ÿ≠ÿßÿ¨Ÿá ÿÆÿßŸÑÿµ üò£ŸÖÿ¥ ÿπÿßÿ±ŸÅ ÿ®ŸÇŸâ üòî   NOT_OFF   NOT_HS\n",
       "4  #ÿßŸÑŸäŸàŸÖ_ÿßŸÑÿßÿ´ŸÜŸäŸÜüëè ŸäŸÇŸàŸÑŸÉ :%90  ŸÖŸÜ ÿßŸÑŸÖÿ≥ŸÑŸÖŸäŸÜ ÿπŸÜÿØŸáŸÖ ...   NOT_OFF   NOT_HS"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df = pd.read_csv('./dataset/OSACT2022-sharedTask-train.csv', usecols=['tweet', 'off_label', 'hs_label'])\n",
    "print(train_dataset_df.describe())\n",
    "train_dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT_OFF    5715\n",
      "OFF        3172\n",
      "Name: off_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='off_label', ylabel='count'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_dataset_df['off_label'].value_counts())\n",
    "sns.countplot(data = train_dataset_df , x='off_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT_HS    7928\n",
      "HS         959\n",
      "Name: hs_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='hs_label', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_dataset_df.loc[train_dataset_df['hs_label'] == 'HS1', 'hs_label'] = 'HS'\n",
    "train_dataset_df.loc[train_dataset_df['hs_label'] == 'HS2', 'hs_label'] = 'HS'\n",
    "train_dataset_df.loc[train_dataset_df['hs_label'] == 'HS3', 'hs_label'] = 'HS'\n",
    "train_dataset_df.loc[train_dataset_df['hs_label'] == 'HS4', 'hs_label'] = 'HS'\n",
    "train_dataset_df.loc[train_dataset_df['hs_label'] == 'HS5', 'hs_label'] = 'HS'\n",
    "train_dataset_df.loc[train_dataset_df['hs_label'] == 'HS6', 'hs_label'] = 'HS'\n",
    "train_dataset_df.loc[(train_dataset_df['hs_label'] == 'NOT_HS'), 'hs_label'] = 'NOT_HS'\n",
    "print(train_dataset_df['hs_label'].value_counts())\n",
    "sns.countplot(data = train_dataset_df , x='hs_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Augmentator\n",
    "TOPK=20 #default=100\n",
    "ACT = 'insert' #\"substitute\"\n",
    "\n",
    "aug_bert = ContextualWordEmbsAug(\n",
    "    model_path= 'UBC-NLP/MARBERT',\n",
    "#     model_path='distilbert-base-uncased', \n",
    "    # device='cuda',\n",
    "    action=ACT, top_k=TOPK)\n",
    "\n",
    "def augment_text(df, augmenter, label_name, label_val, samples=100, pr=0.2, show = 0):\n",
    "    augmenter.aug_p = pr\n",
    "    new_text=[]\n",
    "    \n",
    "    # selecting the minority class samples\n",
    "    df_n = df[df[label_name]==label_val].reset_index(drop=True)\n",
    "\n",
    "    # data augmentation loop\n",
    "    for i in tqdm(np.random.randint(0, len(df_n), samples)):\n",
    "            text = df_n.iloc[i]['tweet']\n",
    "            augmented_text = augmenter.augment(text)\n",
    "            if show:\n",
    "                print(f\"The original text: {text}\")\n",
    "                print(f\"The augmented text: {augmented_text}\")\n",
    "                print('-'*100)\n",
    "            new_text.append(augmented_text)\n",
    "    \n",
    "    # dataframe\n",
    "    new = pd.DataFrame({'tweet':new_text,label_name:label_val})\n",
    "    df = shuffle(pd.concat([df,new]).reset_index(drop=True))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original text: ÿßŸÑÿ±Ÿäÿ≥ ŸäÿÆÿµÿµ Ÿ¢ŸßŸ• ŸÖŸÑŸäÿßÿ± ÿ¨ŸÜŸäŸá ŸÑ ÿ™ŸÜŸÖŸäŸá ÿ¥ÿßŸÖŸÑŸá ŸÑ ÿ≥ŸäŸÜÿßÿ° ....ÿπŸÑÿ¥ÿßŸÜ ÿßÿ≥ÿ±ÿßÿ¶ŸäŸÑ ÿ™ÿ£ÿÆÿ∞ ÿ≥ŸäŸÜÿßÿ° ÿ≥Ÿàÿ®ÿ± ŸÑŸàŸÉÿ≥ ÿπŸÑŸä ŸÖŸÅÿ™ÿßÿßÿßÿ≠ üêëüêè\n",
      "The augmented text: ŸäÿπŸÜŸä ÿßŸÑÿ±Ÿäÿ≥ ŸÑÿßÿ≤ŸÖ ŸäÿÆÿµÿµ Ÿ¢ŸßŸ• ŸÖŸÑŸäÿßÿ± ÿ¨ŸÜŸäŸá ŸÑ ŸÖÿ¥ÿ±Ÿàÿπ ÿ™ŸÜŸÖŸäŸá ÿ¥ÿßŸÖŸÑŸá ÿ¥ÿßŸÖŸÑŸá ŸÑ ÿ¥ÿ®Ÿá ÿ≥ŸäŸÜÿßÿ°.... ÿπŸÑÿ¥ÿßŸÜ ÿßÿ≥ÿ±ÿßŸäŸäŸÑ ÿ™ÿßÿÆÿ∞ ŸÖÿ¥ÿ±Ÿàÿπ ÿ≥ŸäŸÜÿßÿ° ÿ≥Ÿàÿ®ÿ± ŸÑŸàŸÉÿ≥ ÿπŸÑŸä ŸÖŸÅÿ™ÿßÿßÿßÿ≠ [UNK]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The original text: ÿ®ŸÜÿßÿ™ ÿßŸÑÿ¥ÿπÿ®Ÿá ÿπŸÜÿØŸáŸÖ Ÿàÿ≥Ÿàÿßÿ≥ ŸÇŸáÿ±Ÿä ŸÅŸä ÿßŸÑŸÖŸàÿßÿØ Ÿäÿ≥ÿ£ŸÑŸàŸÜ ÿπŸÜ ÿ™ŸÅÿßÿµŸäŸÑ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ üò∑üò∑üò∑ÿÆÿµŸàÿµÿß Ÿàÿ≠ÿØŸá ÿ™ÿ≠ÿ® ÿ™Ÿàÿ≥Ÿàÿ≥ ŸÜŸÅÿ≥Ÿä ÿßÿµŸÅŸÇŸáÿß\n",
      "The augmented text: ÿ®ŸÜÿßÿ™ ÿßŸÑÿ¥ÿπÿ®Ÿá ÿπŸÜÿØŸáŸÖ Ÿàÿ≥Ÿàÿßÿ≥ Ÿà ŸÇŸáÿ±Ÿä ŸÅŸä ÿßŸÑŸÖŸàÿßÿØ ŸàŸÑÿßÿ≤ŸÖ Ÿäÿ≥ÿßŸÑŸàŸÜ ÿπŸÜ ÿ™ŸÅÿßÿµŸäŸÑ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ üò∑üò∑üò∑ÿÆÿµŸàÿµÿß ŸÖÿπ Ÿàÿ≠ÿØŸá ÿ™ÿ≠ÿ® ŸàŸÑÿß ÿ™Ÿàÿ≥Ÿàÿ≥ üòÇüòÇ ŸÜŸÅÿ≥Ÿä ÿßÿµŸÅŸÇŸáÿß\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original text:  ŸÜÿπŸÖ ŸÅÿπŸÑÿßŸã ÿßŸÇŸàŸÑŸáÿß ŸÖŸÜ ÿ™ÿ¨ÿ±ÿ®ÿ© ŸàŸÖŸÜ ÿÆŸÑÿßŸÑ ÿ±ÿ§Ÿäÿ™Ÿä ÿ®ÿ£ŸÜ ÿßŸÑŸÖÿπŸÑŸÖŸäŸÜ ÿ®ÿ≠ÿßÿ¨ÿ© ŸÖÿ≥ÿ™ŸÖÿ±ÿ© ŸÑÿØŸàÿ±ÿßÿ™ ÿ™ÿ´ŸÇŸäŸÅŸäÿ© ŸäÿπŸÜŸä ŸÖŸà ŸÖÿπŸÇŸàŸÑÿ© ŸÉŸÑ ÿßŸÑŸÖÿπŸÑŸÖÿßÿ™ ÿßŸÑŸÑŸä ÿ®ÿßŸÑŸÖÿØÿ±ÿ≥ÿ© ÿ™ÿ≠ÿ≥ŸáŸÖ ŸÖÿ¥ ŸÖÿ™ÿπŸÑŸÖÿßÿ™ ŸÖŸÜ ÿ∑ÿ±ŸäŸÇÿ© ŸÉŸÑÿßŸÖŸáŸÖ Ÿàÿ™ÿπÿßŸÖŸÑŸáŸÖ ŸÖÿπ ÿßŸÑÿ∑ÿßŸÑÿ®ÿßÿ™ ÿ¥Ÿäÿ° ŸÅÿ∏Ÿäÿπ ŸàÿßŸÑŸÑŸáüò£\n",
      "The augmented text: ÿßŸä ŸÜÿπŸÖ ŸÅÿπŸÑÿß ÿßŸÇŸàŸÑŸáÿß ŸÖŸÜ ÿ™ÿ¨ÿ±ÿ®ÿ© ŸàŸÖŸÜ ÿÆŸÑÿßŸÑ ÿ±ŸàŸäÿ™Ÿä ÿ®ÿßŸÜ ÿßŸÑŸÖÿπŸÑŸÖŸäŸÜ ÿ®ÿ≠ÿßÿ¨ÿ© Ÿàÿ®ÿ¥ŸÉŸÑ ŸÖÿ≥ÿ™ŸÖÿ±ÿ© ŸÑÿØŸàÿ±ÿßÿ™ ÿ™ÿ´ŸÇŸäŸÅŸäÿ© ŸäÿπŸÜŸä ŸÖŸà ŸÖÿπŸÇŸàŸÑÿ© ŸÑŸà ŸÉŸÑ ÿßŸÑŸÖÿπŸÑŸÖÿßÿ™ ÿ≤Ÿä ÿßŸÑŸÑŸä ÿπŸÜÿØŸÜÿß ÿ®ÿßŸÑŸÖÿØÿ±ÿ≥ÿ© ÿ™ÿ≠ÿ≥ŸáŸÖ ÿ≠ÿ™Ÿâ ŸÖÿ¥ ŸÖÿ™ÿπŸÑŸÖÿßÿ™ ŸÖŸÜ ÿ∑ÿ±ŸäŸÇÿ© ŸÉŸÑÿßŸÖŸáŸÖ Ÿàÿ™ÿπÿßŸÖŸÑŸáŸÖ ÿßŸÑÿ≥ŸÑÿ®Ÿä ŸÖÿπ ÿßŸÑÿ∑ÿßŸÑÿ®ÿßÿ™ ÿ¥Ÿäÿ° ÿ¨ÿØ ŸÅÿ∏Ÿäÿπ ŸàÿßŸÑŸÑŸáüò£\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The original text: ÿßÿ®ÿ∫Ÿâ ÿßŸÑŸä ŸÇÿµÿ© ÿ¥ÿπÿ±Ÿá Ÿàÿ≥Ÿàÿ™ ŸÅŸäŸá ŸÉÿ∞ÿß ŸàŸäŸÜŸáÿß ÿßŸÑŸÉŸÑÿ®Ÿá ŸàŸäŸÜŸáÿß ÿ≠ÿ≥ÿ®Ÿä ÿπŸÑŸäŸÉ ŸÖÿπ ŸáÿßŸÑÿµÿ®ÿßÿ≠üò£üíî \n",
      "The augmented text: ÿ®ŸÖŸàÿ™ ÿßÿ®ÿ∫Ÿâ ÿßŸÑŸä ÿπÿ¨ÿ®Ÿá ŸÇÿµÿ© ÿ¥ÿπÿ±Ÿá Ÿàÿ≥Ÿàÿ™ ÿ™ÿ≥ŸàŸä ŸÅŸäŸá ŸÉÿ∞ÿß ŸàŸäŸÜŸáÿß ÿßŸÑŸÉŸÑÿ®Ÿá ŸàŸäŸÜŸáÿß ÿßŸÑŸÉŸÑÿ®Ÿá ÿ≠ÿ≥ÿ®Ÿä ÿπŸÑŸäŸÉ ŸÖÿπ ŸáÿßŸÑÿµÿ®ÿßÿ≠üò£üíî\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The original text: ÿßŸÖÿß ÿ®ÿ¥ŸàŸÅ Ÿàÿßÿ≠ÿØŸá ŸÖÿ∑ŸÑÿπŸá ÿ¥ÿπÿ±ÿßŸäŸá Ÿàÿßÿ≠ÿØŸá ÿ®ÿ±Ÿá ÿßŸÑÿ∑ÿ±ÿ≠Ÿá ÿ®ÿ®ŸÇŸá ÿπÿßŸäÿ≤ ÿßÿ™ŸÅ ŸÅŸä Ÿàÿ¥Ÿáÿßüò°üò°ŸÑÿßŸÖÿß ÿ™ÿ®ŸÇŸä ŸÇÿØŸá ŸÑÿßŸÖÿß ÿ™ŸÇŸÑÿπŸäŸá ÿÆÿßŸÑÿµüò°üò°\n",
      "The augmented text: ÿßŸÖÿß ÿ®ÿ¥ŸàŸÅ ÿµŸàÿ± Ÿàÿßÿ≠ÿØŸá ÿ®ÿ¥ŸàŸÅŸáÿß ŸÖÿ∑ŸÑÿπŸá ÿ¥ÿπÿ±ÿßŸäŸá Ÿàÿßÿ≠ÿØŸá ÿ®ÿ±Ÿá ÿ®ÿ™ÿßÿπÿ™ ÿßŸÑÿ∑ÿ±ÿ≠Ÿá ÿßŸÜÿß ÿ®ÿ®ŸÇŸá ÿπÿßŸäÿ≤ ÿßÿ™ŸÅ Ÿàÿ¥Ÿá ŸÅŸä Ÿàÿ¥Ÿáÿßüò°üò°ŸÑÿßŸÖÿß ÿ™ÿ®ŸÇŸä ŸÇÿØŸá ŸÑÿßŸÖÿß ÿ™ŸÇŸÑÿπŸäŸá ÿÆÿßŸÑÿµüò°üò°\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#show sample of augmented offensive tweets\n",
    "aug_df = augment_text(train_dataset_df, aug_bert, 'off_label', label_val ='OFF', samples=5, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original text:  ŸàÿØŸä ŸäŸÖÿ≥ŸÉŸàŸÜŸÉ ÿßŸÜÿ™ ŸàÿßŸÖÿ´ÿßŸÑŸá ŸàŸäÿÆŸÑŸàŸÜŸÉŸÉŸÖ ÿπÿ®ÿ±Ÿá ŸÑŸÉŸÑ ŸÖÿπÿ™ÿ®ÿ± ŸÅÿßŸÇÿØ ŸÑŸÑÿ±ÿ¨ŸàŸÑŸá üòéŸÖÿßÿ™ŸÇŸàŸÖ ÿ±ÿ¨ŸàŸÑÿ™ŸÉŸÖ ÿßŸÑÿß ÿπ ÿßŸÜÿ´Ÿâ ÿ®ÿ≥ üëéüèª\n",
      "The augmented text: ŸàÿØŸä ÿ®ÿπÿØ ŸäŸÖÿ≥ŸÉŸàŸÜŸÉ ÿßŸÜÿ™ ŸàÿßŸÖÿ´ÿßŸÑŸá ŸàŸäÿÆŸÑŸàŸÜŸÉŸÉŸÖ ÿπÿ®ÿ±Ÿá ŸÑŸÉŸÑ ÿ¥ÿÆÿµ ŸÖÿπÿ™ÿ®ÿ± ÿå ŸÅÿßŸÇÿØ ÿßŸÑÿ∂ŸÖŸäÿ± ŸÑŸÑÿ±ÿ¨ŸàŸÑŸá üòéŸÖÿßÿ™ŸÇŸàŸÖ ÿ±ÿ¨ŸàŸÑÿ™ŸÉŸÖ ÿßŸÑÿß ÿ®ÿßŸÑÿ∂ÿ±ÿ® ÿπ ÿßŸÜÿ´Ÿâ ÿ®ÿ≥ üëéüèª\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The original text:   ŸÅŸä ÿ£Ÿàÿ±Ÿàÿ®ÿß ÿ™ŸÖÿ± ÿπŸÑŸäŸÉ ÿßŸÑÿ®ŸÜÿ™ ŸÖÿπ ŸÇŸÑŸäŸÑ ŸÖŸÜ ÿßŸÑŸÖŸÉŸäÿßÿ¨. ÿ£ŸÖÿß ÿπŸÜÿØŸÜÿß ŸäŸÖÿ± ÿπŸÑŸäŸÉ ÿßŸÑŸÖŸÉŸäÿßÿ¨ ŸÖÿπ ŸÇŸÑŸäŸÑ ŸÖŸÜ ÿßŸÑÿ®ŸÜÿ™ üåöüî™üòÇüòÇ\n",
      "The augmented text: ŸÅŸä ÿßŸàÿ±Ÿàÿ®ÿß ÿ™ŸÖÿ± ÿπŸÑŸäŸÉ ŸÖŸÉŸäÿßÿ¨ ÿßŸÑÿ®ŸÜÿ™ ŸÖÿπ ŸÇŸÑŸäŸÑ ŸÖŸÜ ÿßŸÑŸÖŸÉŸäÿßÿ¨. ÿßŸÖÿß ÿ≠ŸÜÿß ÿπŸÜÿØŸÜÿß ÿπÿßÿØŸä ŸäŸÖÿ± ÿπŸÑŸäŸÉ ÿßŸÑŸÖŸÉŸäÿßÿ¨ ŸÉÿßŸÖŸÑ ŸÖÿπ ÿ¥ŸàŸäÿ© ŸÇŸÑŸäŸÑ ŸÖŸÜ ÿßŸÑÿ®ŸÜÿ™ üåöüî™üòÇüòÇ\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The original text:  ÿ®ÿ™ÿπŸÖŸÑŸàÿß ŸÅ ÿØŸäŸÉ ÿ£ÿ®ŸàŸÜÿß ŸÉÿØŸá ŸÑŸäŸá ŸáŸà ÿ•ÿ≠ŸÜÿß ŸÉŸÅÿ±ÿ© ŸàŸÑÿßŸäŸáŸàÿØ... Ÿàÿ±ÿ®ŸÜÿß ÿ•ÿ≠ŸÜÿß ŸÖÿßÿ¥ŸäŸäŸÜ ÿ®ÿßŸÑÿπŸÑÿßÿ¨ üò°üò°üò°üò°\n",
      "The augmented text: ÿ®ÿ™ÿπŸÖŸÑŸàÿß ÿßŸäŸá ŸÅ ÿßÿ®ŸÜ ÿØŸäŸÉ ÿßÿ®ŸàŸÜÿß Ÿäÿßÿ¨ŸÖÿßÿπÿ© ŸÉÿØŸá ŸÑŸäŸá ŸáŸà ÿßÿ≠ŸÜÿß ŸÉŸÅÿ±ÿ© ŸàŸÑÿßŸäŸáŸàÿØ... Ÿàÿ±ÿ®ŸÜÿß ÿßÿ≠ŸÜÿß ŸÖÿßÿ¥ŸäŸäŸÜ ÿ®ÿßŸÑÿπŸÑÿßÿ¨ ÿßŸáŸà üò°üò°üò°üò°\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original text:  ÿ≠ŸÑŸàŸàŸàÿ® ÿ¨ÿØÿß ÿ¨ÿØÿß ÿ¨ÿØÿß ŸÑÿπŸäŸàŸÜ ÿßŸäŸÅÿßÿßŸÜŸÉÿß Ÿ§Ÿ®Ÿ† ŸÖŸÑŸäÿßÿ± ÿØŸàŸÑÿßÿ± ÿπŸÇÿ®Ÿáÿß ÿÆŸÑŸàŸàŸàŸÉ ÿ™ÿØŸÅÿπ ÿ∂ÿ±ÿßÿ¶ÿ® Ÿäÿßÿß üêëüêë\n",
      "The augmented text: ŸÇŸàŸàŸÑ ÿ≠ŸÑŸàŸàŸàÿ® ÿ¨ÿØÿß ÿ¨ÿØÿß ÿ¨ÿØÿß ŸÑÿπŸäŸàŸÜ ÿßŸäŸÅÿßÿßŸÜŸÉÿß Ÿ§Ÿ®Ÿ† ŸÖŸÑŸäÿßÿ± ÿØŸàŸÑÿßÿ± ÿπŸÇÿ®Ÿáÿß ŸÇŸàŸÑŸàÿß ÿÆŸÑŸàŸàŸàŸÉ ÿ™ÿØŸÅÿπ ÿßŸàŸÑ ÿ∂ÿ±ÿßŸäÿ® ÿπŸÑŸäŸÜÿß Ÿäÿßÿß ÿ≠ŸÖÿßÿ± üêëüêë\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The original text: ÿßŸÇÿ≥ŸÖ ÿ® ÿßŸÑŸÑŸá ŸÜÿßÿ≥ ÿ£ÿµÿ®ÿ≠ÿ™ ŸÖŸÇÿ±ŸÅÿ© ÿ®ÿ±ŸÖŸä ÿßŸÑÿ£ÿ≥ÿßŸÖŸä Ÿà ÿßŸÑÿ™ŸáŸÖ ÿπ ŸÉŸÑ ŸÖŸÜ ŸÉÿßŸÜ ŸÑŸá ŸÅŸÉÿ± ÿ≠ÿ± .. Ÿäÿ¥ÿ™Ÿà ŸÖÿ∑ÿ®ŸÑŸäŸÜ Ÿà ŸÇÿ∑Ÿäÿπ .. ÿßŸÜŸÇŸÑÿπŸà ÿßŸÑŸÑŸá ŸäŸÇÿ±ŸÅŸÉŸÖ ŸÅÿßÿ∂ ÿßŸÑŸÉŸäŸÑ ÿ®ŸÜÿß ŸÖŸÜŸÉŸÖ !!! üò†üò∑\n",
      "The augmented text: ÿßŸÇÿ≥ŸÖ ÿ® ÿ∫ÿ∂ÿ® ÿßŸÑŸÑŸá ŸÜÿßÿ≥ ÿßÿµÿ®ÿ≠ÿ™ ŸÖŸÇÿ±ŸÅÿ© ÿ≠ÿ™Ÿâ ÿ®ÿ±ŸÖŸä ÿßŸÑÿßÿ≥ÿßŸÖŸä Ÿà ÿßŸÑÿ™ŸáŸÖ ÿπ ŸÉŸÑ ŸÖŸÜ ŸáŸà ŸÉÿßŸÜ ŸÑŸá ŸÅŸÉÿ± ÿßŸà ÿ≠ÿ±.. Ÿäÿ¥ÿ™Ÿà ŸÖÿ∑ÿ®ŸÑŸäŸÜ ÿ≠ŸÖŸäÿ± Ÿà ŸÇÿ∑Ÿäÿπ.. ÿßŸÜŸÇŸÑÿπŸà ÿßŸÑŸÑŸá ŸÑÿß ŸäŸÇÿ±ŸÅŸÉŸÖ ŸÅÿßÿ∂ ÿßŸÑŸÉŸäŸÑ ÿ®ŸÜÿß ÿßŸÑŸÉŸäŸÑ ŸÖŸÜŸÉŸÖ!!! üòí üò†üò∑\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#show sample of augmented hate speech tweets\n",
    "aug_df = augment_text(train_dataset_df, aug_bert, 'hs_label', label_val ='HS', samples=5, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2543/2543 [17:44<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#augment offensive tweets\n",
    "off_count = train_dataset_df.loc[train_dataset_df['off_label'] == 'OFF'].shape[0]\n",
    "not_off_count = train_dataset_df.loc[train_dataset_df['off_label'] == 'NOT_OFF'].shape[0]\n",
    "num_samples = not_off_count - off_count\n",
    "off_aug_df = augment_text(train_dataset_df, aug_bert,label_name='off_label', label_val ='OFF', samples=num_samples, show=False)\n",
    "off_aug_df[\"tweet\"] = [string.replace(\"[UNK]\", \"\")  for string in off_aug_df['tweet']]\n",
    "off_aug_df['tweet'] = off_aug_df['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6969/6969 [1:07:21<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#augment hate speech tweets\n",
    "hs_count = train_dataset_df.loc[train_dataset_df['hs_label'] == 'HS'].shape[0]\n",
    "not_hs_count = train_dataset_df.loc[train_dataset_df['hs_label'] == 'NOT_HS'].shape[0]\n",
    "num_samples = not_hs_count - hs_count\n",
    "hs_aug_df = augment_text(train_dataset_df, aug_bert, label_name='hs_label', label_val='HS', samples=num_samples, show=False)\n",
    "hs_aug_df['tweet'] = [string.replace(\"[UNK]\", \"\") for string in hs_aug_df['tweet']]\n",
    "hs_aug_df['tweet'] = hs_aug_df['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 15:01:54.391504: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-04-13 15:01:54.391631: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: kirollos-G3-3500\n",
      "2022-04-13 15:01:54.391666: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: kirollos-G3-3500\n",
      "2022-04-13 15:01:54.404566: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.47.3\n",
      "2022-04-13 15:01:54.404710: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.47.3\n",
      "2022-04-13 15:01:54.404747: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.47.3\n",
      "2022-04-13 15:01:54.406387: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-13 15:01:54.830154: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 307200000 exceeds 10% of free system memory.\n",
      "2022-04-13 15:01:55.448030: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 307200000 exceeds 10% of free system memory.\n",
      "2022-04-13 15:01:55.663415: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 307200000 exceeds 10% of free system memory.\n",
      "2022-04-13 15:02:10.193359: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 307200000 exceeds 10% of free system memory.\n",
      "2022-04-13 15:02:10.340514: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 307200000 exceeds 10% of free system memory.\n",
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at UBC-NLP/MARBERT.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import tensorflow as tf\n",
    "marbert_model_path = 'UBC-NLP/MARBERT'\n",
    "tokenizer = AutoTokenizer.from_pretrained(marbert_model_path, from_tf=True)\n",
    "marbert_model = TFAutoModel.from_pretrained(marbert_model_path, output_hidden_states=True)\n",
    "\n",
    "def bert_tokenize(texts: str) -> list:\n",
    "    max_len = 0\n",
    "    for text in texts:\n",
    "        max_len = max(len(tokenizer.tokenize(f'[CLS] {text} [SEP]')), max_len)\n",
    "    tokens = tokenizer(texts, padding='max_length', truncation=True, max_length=max_len)\n",
    "    return (tokens['input_ids'], tokens['attention_mask'], tokens['token_type_ids'])\n",
    "\n",
    "def get_embeddings(tokens):\n",
    "    ids = tf.convert_to_tensor(tokens[0])\n",
    "    mask = tf.convert_to_tensor(tokens[1])\n",
    "    type_ids = tf.convert_to_tensor(tokens[2])\n",
    "    hidden_states = marbert_model(input_ids=ids, attention_mask=mask, token_type_ids=type_ids)[2]\n",
    "    sentence_embd = tf.reduce_mean(tf.reduce_sum(tf.stack(hidden_states[-4:]), axis = 0), axis=1)\n",
    "    return sentence_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11430,)\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "#prepare offensive task labels\n",
    "off_aug_df.loc[off_aug_df['off_label'] == 'OFF', 'off_label'] = 1\n",
    "off_aug_df.loc[off_aug_df['off_label'] == 'NOT_OFF', 'off_label'] = 0\n",
    "del off_aug_df['hs_label']\n",
    "off_aug_df['off_label'] = off_aug_df['off_label'].astype(np.int32)\n",
    "y_train_offensive = off_aug_df['off_label'].values\n",
    "print(y_train_offensive.shape)\n",
    "print(y_train_offensive.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training features for hate speech task\n",
    "text_offensive = off_aug_df['tweet'].values \n",
    "batch_size = 64\n",
    "train_num_batches = text_offensive.shape[0] // batch_size\n",
    "train_rem = text_offensive.shape[0] % batch_size\n",
    "\n",
    "x_train_offensive = np.empty(shape=(text_offensive.shape[0], 768), dtype=np.float64)\n",
    "for batch_step in tqdm(range(1, train_num_batches), desc='getting training features..'):\n",
    "    i = batch_step - 1\n",
    "    tokens = bert_tokenize(list(text_offensive[i * batch_size: batch_step * batch_size]))\n",
    "    x_train_offensive[i * batch_size : batch_step * batch_size] = get_embeddings(tokens)\n",
    "\n",
    "if train_rem != 0:\n",
    "    tokens = bert_tokenize(list(text_offensive[text_offensive.shape[0] - train_rem: ]))\n",
    "    x_train_offensive[text_offensive.shape[0] - train_rem: ] = get_embeddings(tokens)\n",
    "\n",
    "print(x_train_offensive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15856,)\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "#prepare hate speech task labels\n",
    "hs_aug_df.loc[hs_aug_df['hs_label'] == 'HS', 'hs_label'] = 1\n",
    "hs_aug_df.loc[hs_aug_df['hs_label'] == 'NOT_HS', 'hs_label'] = 0\n",
    "del hs_aug_df['off_label']\n",
    "hs_aug_df['hs_label'] = hs_aug_df['hs_label'].astype(np.int32)\n",
    "y_train_hs = hs_aug_df['hs_label'].values\n",
    "print(y_train_hs.shape)\n",
    "print(y_train_hs.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting training features..: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 246/246 [30:39<00:00,  7.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15856, 768)\n"
     ]
    }
   ],
   "source": [
    "# extract training features for hate speech task\n",
    "text_hs = hs_aug_df['tweet'].values \n",
    "batch_size = 64\n",
    "train_num_batches = text_hs.shape[0] // batch_size\n",
    "train_rem = text_hs.shape[0] % batch_size\n",
    "\n",
    "x_train_hs = np.empty(shape=(text_hs.shape[0], 768), dtype=np.float64)\n",
    "for batch_step in tqdm(range(1, train_num_batches), desc='getting training features..'):\n",
    "    i = batch_step - 1\n",
    "    tokens = bert_tokenize(list(text_hs[i * batch_size: batch_step * batch_size]))\n",
    "    x_train_hs[i * batch_size : batch_step * batch_size] = get_embeddings(tokens)\n",
    "\n",
    "if train_rem != 0:\n",
    "    tokens = bert_tokenize(list(text_hs[text_hs.shape[0] - train_rem: ]))\n",
    "    x_train_hs[text_hs.shape[0] - train_rem: ] = get_embeddings(tokens)\n",
    "\n",
    "print(x_train_hs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read development dataset and prepare offensive and hate speech labels\n",
    "dev_dataset_df = pd.read_csv('./dataset/OSACT2022-sharedTask-dev.csv', usecols=['tweet','off_label', 'hs_label'])\n",
    "dev_dataset_df.loc[dev_dataset_df['off_label'] == 'OFF', 'off_label'] = 1\n",
    "dev_dataset_df.loc[dev_dataset_df['off_label'] == 'NOT_OFF', 'off_label'] = 0\n",
    "dev_dataset_df['off_label'] = dev_dataset_df['off_label'].astype(np.int32)\n",
    "y_dev_offensive = dev_dataset_df['off_label'].values\n",
    "\n",
    "dev_dataset_df.loc[dev_dataset_df['hs_label'] == 'HS1', 'hs_label'] = 1\n",
    "dev_dataset_df.loc[dev_dataset_df['hs_label'] == 'HS2', 'hs_label'] = 1\n",
    "dev_dataset_df.loc[dev_dataset_df['hs_label'] == 'HS3', 'hs_label'] = 1\n",
    "dev_dataset_df.loc[dev_dataset_df['hs_label'] == 'HS4', 'hs_label'] = 1\n",
    "dev_dataset_df.loc[dev_dataset_df['hs_label'] == 'HS5', 'hs_label'] = 1\n",
    "dev_dataset_df.loc[dev_dataset_df['hs_label'] == 'HS6', 'hs_label'] = 1\n",
    "dev_dataset_df.loc[(dev_dataset_df['hs_label'] == 'NOT_HS'), 'hs_label'] = 0\n",
    "dev_dataset_df['hs_label'] = dev_dataset_df['hs_label'].astype(np.int32)\n",
    "y_dev_hs = dev_dataset_df['hs_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting dev features..: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:47<00:00,  5.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1270, 768)\n"
     ]
    }
   ],
   "source": [
    "#extract development dataset features\n",
    "text_offensive = dev_dataset_df['tweet'].values \n",
    "batch_size = 64\n",
    "dev_num_batches = text_offensive.shape[0] // batch_size\n",
    "dev_rem = text_offensive.shape[0] % batch_size\n",
    "\n",
    "x_dev = np.empty(shape=(text_offensive.shape[0], 768), dtype=np.float64)\n",
    "for batch_step in tqdm(range(1, dev_num_batches), desc='getting dev features..'):\n",
    "    i = batch_step - 1\n",
    "    tokens = bert_tokenize(list(text_offensive[i * batch_size: batch_step * batch_size]))\n",
    "    x_dev[i * batch_size : batch_step * batch_size] = get_embeddings(tokens)\n",
    "\n",
    "if dev_rem != 0:\n",
    "    tokens = bert_tokenize(list(text_offensive[text_offensive.shape[0] - dev_rem: ]))\n",
    "    x_dev[text_offensive.shape[0] - dev_rem: ] = get_embeddings(tokens)\n",
    "\n",
    "print(x_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, change: 1.00000000\n",
      "Epoch 2, change: 0.20669558\n",
      "Epoch 3, change: 0.10823747\n",
      "Epoch 4, change: 0.06977143\n",
      "Epoch 5, change: 0.04783693\n",
      "Epoch 6, change: 0.02658286\n",
      "Epoch 7, change: 0.01648776\n",
      "Epoch 8, change: 0.01105328\n",
      "Epoch 9, change: 0.00894443\n",
      "Epoch 10, change: 0.00493904\n",
      "Epoch 11, change: 0.00387966\n",
      "Epoch 12, change: 0.00325783\n",
      "Epoch 13, change: 0.00242496\n",
      "Epoch 14, change: 0.00170599\n",
      "Epoch 15, change: 0.00131166\n",
      "Epoch 16, change: 0.00113192\n",
      "Epoch 17, change: 0.00081929\n",
      "Epoch 18, change: 0.00065565\n",
      "Epoch 19, change: 0.00047070\n",
      "Epoch 20, change: 0.00039170\n",
      "Epoch 21, change: 0.00027360\n",
      "Epoch 22, change: 0.00021646\n",
      "Epoch 23, change: 0.00017753\n",
      "Epoch 24, change: 0.00012184\n",
      "Epoch 25, change: 0.00010307\n",
      "convergence after 26 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, solver='saga', verbose=2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression model for offensive task\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_offensive = scaler.fit_transform(x_train_offensive, y_train_offensive)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_offensive, y_train_offensive, test_size=0.3)\n",
    "\n",
    "offensive_lr_model = LogisticRegression(verbose=2, solver='saga', C=1e-3)\n",
    "\n",
    "offensive_lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate logistic regression on training, test and development datasets for offensive task\n",
    "x_dev_offensive = scaler.fit(x_dev)\n",
    "print('train data confusion matrix:')\n",
    "train_data_conf_matrix = classification_report(y_train, offensive_lr_model.predict(x_train), target_names=['not_off', 'off'])\n",
    "print(train_data_conf_matrix)\n",
    "print('test data confusion matrix:')\n",
    "test_data_conf_matrix = classification_report(y_test, offensive_lr_model.predict(x_test), target_names=['not_off', 'off'])\n",
    "print(test_data_conf_matrix)\n",
    "print('dev data confusion matrix:')\n",
    "dev_data_conf_matrix = classification_report(y_dev_offensive, offensive_lr_model.predict(x_dev_offensive), target_names=['not_off', 'off'])\n",
    "print(dev_data_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   47.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_samples=0.4, verbose=2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest model for offensive task\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_offensive = scaler.fit_transform(x_train_offensive, y_train_offensive)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_offensive, y_train_offensive, test_size=0.3)\n",
    "\n",
    "offensive_rf_model = RandomForestClassifier(verbose=2, max_samples=0.4)\n",
    "\n",
    "offensive_rf_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate random forest on training, test and development datasets for offensive task\n",
    "x_dev_offensive = scaler.fit(x_dev)\n",
    "print('train data confusion matrix:')\n",
    "train_data_conf_matrix = classification_report(y_train, offensive_rf_model.predict(x_train), target_names=['not_off', 'off'])\n",
    "print(train_data_conf_matrix)\n",
    "print('test data confusion matrix:')\n",
    "test_data_conf_matrix = classification_report(y_test, offensive_rf_model.predict(x_test), target_names=['not_off', 'off'])\n",
    "print(test_data_conf_matrix)\n",
    "print('dev data confusion matrix:')\n",
    "dev_data_conf_matrix = classification_report(y_dev_offensive, offensive_rf_model.predict(x_dev_offensive), target_names=['not_off', 'off'])\n",
    "print(dev_data_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, change: 1.00000000\n",
      "Epoch 2, change: 0.22245601\n",
      "Epoch 3, change: 0.13065225\n",
      "Epoch 4, change: 0.06529777\n",
      "Epoch 5, change: 0.04371365\n",
      "Epoch 6, change: 0.03118205\n",
      "Epoch 7, change: 0.01940550\n",
      "Epoch 8, change: 0.01335161\n",
      "Epoch 9, change: 0.01064205\n",
      "Epoch 10, change: 0.00771064\n",
      "Epoch 11, change: 0.00414935\n",
      "Epoch 12, change: 0.00285662\n",
      "Epoch 13, change: 0.00210780\n",
      "Epoch 14, change: 0.00152659\n",
      "Epoch 15, change: 0.00118896\n",
      "Epoch 16, change: 0.00093127\n",
      "Epoch 17, change: 0.00068015\n",
      "Epoch 18, change: 0.00054178\n",
      "Epoch 19, change: 0.00038536\n",
      "Epoch 20, change: 0.00028793\n",
      "Epoch 21, change: 0.00021724\n",
      "Epoch 22, change: 0.00016804\n",
      "Epoch 23, change: 0.00012574\n",
      "convergence after 24 epochs took 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, solver='saga', verbose=2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression model for hate speech task\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_hs = scaler.fit_transform(x_train_hs, y_train_hs)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_hs, y_train_hs, test_size=0.3)\n",
    "\n",
    "hs_lr_model = LogisticRegression(verbose=2, solver='saga', C=1e-3)\n",
    "\n",
    "hs_lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate logistic regression on training, test and development datasets for hate speech task\n",
    "x_dev_hs = scaler.fit(x_dev)\n",
    "print('train data confusion matrix:')\n",
    "train_data_conf_matrix = classification_report(y_train, hs_lr_model.predict(x_train), target_names=['not_hs', 'hs'])\n",
    "print(train_data_conf_matrix)\n",
    "print('test data confusion matrix:')\n",
    "test_data_conf_matrix = classification_report(y_test, hs_lr_model.predict(x_test), target_names=['not_hs', 'hs'])\n",
    "print(test_data_conf_matrix)\n",
    "print('dev data confusion matrix:')\n",
    "dev_data_conf_matrix = classification_report(y_dev_offensive, hs_lr_model.predict(x_dev_hs), target_names=['not_hs', 'hs'])\n",
    "print(dev_data_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_samples=0.4, verbose=2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest model for hate speech task\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_hs = scaler.fit_transform(x_train_hs, y_train_hs)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_hs, y_train_hs, test_size=0.3)\n",
    "\n",
    "hs_rf_model = RandomForestClassifier(verbose=2, max_samples=0.4)\n",
    "\n",
    "hs_rf_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate random forest on training, test and development datasets for hate speech task\n",
    "x_dev_hs = scaler.fit(x_dev)\n",
    "print('train data confusion matrix:')\n",
    "train_data_conf_matrix = classification_report(y_train, hs_rf_model.predict(x_train), target_names=['not_hs', 'hs'])\n",
    "print(train_data_conf_matrix)\n",
    "print('test data confusion matrix:')\n",
    "test_data_conf_matrix = classification_report(y_test, hs_rf_model.predict(x_test), target_names=['not_hs', 'hs'])\n",
    "print(test_data_conf_matrix)\n",
    "print('dev data confusion matrix:')\n",
    "dev_data_conf_matrix = classification_report(y_dev_offensive, hs_rf_model.predict(x_dev_hs), target_names=['not_hs', 'hs'])\n",
    "print(dev_data_conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
